# -*- coding: utf-8 -*-
"""tei2html.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1vTAUXvE4nCkB5pI9LqWKUkAUDpKhnkHg
"""

import re
import os
import unicodedata
import zipfile


# Константы
ALLOWED_PREFIX_SYMBOLS = {
    '\uf04b',  # новое слово
    '\uf04a',  # слово, выпавшее из употребления
    '\uf048',  # слово, выходящее из употребления
    '\uf044',  # новое слово, в XVIII в. вышедшее из употребления
    '\u22c6',  # ⋆ - слово, расширившее употребление
}

PUA_RANGE = range(0xE000, 0xF900)


def is_allowed_prefix_char(char):
    """Проверяет, допустим ли символ в префиксе перед заголовком статьи."""
    if char.isspace():
        return True
    if char in ALLOWED_PREFIX_SYMBOLS:
        return True
    if ord(char) in PUA_RANGE:
        return True
    return False


def is_uppercase_heading(text):
    """Проверяет, является ли текст заголовком статьи (все буквы заглавные)."""
    text_no_accents = text.replace('\u0301', '')

    roman_pattern = r'^[IVXLCDM]+[\.\,\s]*$'
    if re.match(roman_pattern, text_no_accents.strip()):
        return False

    letters = [c for c in text_no_accents if c.isalpha()]

    if not letters:
        return False

    if len(letters) == 1:
        return False

    for letter in letters:
        if letter.islower():
            return False

    return True


def extract_headword(text):
    """Извлекает слово-заголовок из текста для имени файла."""
    result = text.rstrip('., ')  # убираем точки, запятые и пробелы в конце
    return result if result else "UNKNOWN"


def parse_xml_entries(xml_content):
    """Разбирает XML на отдельные статьи."""
    entries = []

    p_pattern = re.compile(r'<p>(.*?)</p>', re.DOTALL)

    entry_start_pattern = re.compile(
        r'^([\s\uf044\uf048\uf04a\uf04b\u22c6]*)'
        r'<hi\s+rendition="simple:bold">'
        r'([^<]+)'
        r'</hi>',
        re.UNICODE
    )

    all_paragraphs = list(p_pattern.finditer(xml_content))

    current_entry_parts = []
    current_headword = None
    current_prefix = ""

    for i, match in enumerate(all_paragraphs):
        p_content = match.group(1)
        full_p = match.group(0)

        entry_match = entry_start_pattern.match(p_content)

        is_new_entry = False
        if entry_match:
            prefix = entry_match.group(1)
            heading_text = entry_match.group(2)

            prefix_valid = all(is_allowed_prefix_char(c) for c in prefix)

            if prefix_valid and is_uppercase_heading(heading_text):
                is_new_entry = True
                new_prefix = prefix.strip()
                new_headword = extract_headword(heading_text)

        if is_new_entry:
            if current_headword and current_entry_parts:
                entry_content = '\n'.join(current_entry_parts)
                entries.append((current_headword, current_prefix, entry_content))

            current_headword = new_headword
            current_prefix = new_prefix
            current_entry_parts = [full_p]
        else:
            if current_headword:
                current_entry_parts.append(full_p)

    if current_headword and current_entry_parts:
        entry_content = '\n'.join(current_entry_parts)
        entries.append((current_headword, current_prefix, entry_content))

    return entries


def convert_tei_to_html_span(content):
    """Конвертирует TEI разметку в HTML с inline стилями."""
    # Bold
    content = re.sub(
        r'<hi\s+rendition="simple:bold">(.*?)</hi>',
        "<span style=\"font-family:'Times New Roman'; font-weight:bold\">\\1</span>",
        content,
        flags=re.DOTALL
    )

    # Italic
    content = re.sub(
        r'<hi\s+rendition="simple:italic">(.*?)</hi>',
        "<span style=\"font-family:'Times New Roman'; font-style:italic\">\\1</span>",
        content,
        flags=re.DOTALL
    )

    # Superscript
    content = re.sub(
        r'<hi\s+rendition="simple:superscript">(.*?)</hi>',
        "<span style=\"line-height:115%; font-family:'Times New Roman'; font-size:9.33pt; vertical-align:super\">\\1</span>",
        content,
        flags=re.DOTALL
    )

    # Letter spacing
    content = re.sub(
        r'<hi\s+rendition="simple:letterspace">(.*?)</hi>',
        "<span style=\"font-family:'Times New Roman'; letter-spacing:2pt\">\\1</span>",
        content,
        flags=re.DOTALL
    )

    # Subscript
    content = re.sub(
        r'<hi\s+rendition="simple:subscript">(.*?)</hi>',
        "<span style=\"line-height:115%; font-family:'Times New Roman'; font-size:9.33pt; vertical-align:sub\">\\1</span>",
        content,
        flags=re.DOTALL
    )

    return content


def sanitize_filename(filename):
    """Делает имя файла безопасным для файловой системы."""
    # NFC - объединяет буквы с ударениями в один символ (сохраняет ударения!)
    filename = unicodedata.normalize('NFC', filename)

    # Заменяем только опасные символы для файловой системы
    unsafe_chars = '<>:"/\\|?*'
    for char in unsafe_chars:
        filename = filename.replace(char, '_')

    # Ограничиваем длину
    filename = filename[:200]

    return filename


def create_html_page(headword, prefix, content):
    """Создаёт полную HTML-страницу для одной словарной статьи."""
    prefix_html = ""
    if prefix:
        prefix_html = f'<div style="margin-bottom: 10px; color: #666;">[Префикс: {prefix}]</div>'

    html = f"""<!DOCTYPE html>
<html lang="ru">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>{headword}</title>
    <style>
        body {{
            font-family: 'Times New Roman', serif;
            font-size: 14pt;
            line-height: 115%;
            margin: 2cm;
        }}
    </style>
</head>
<body>
    {prefix_html}
    <div>
        {content}
    </div>
</body>
</html>"""

    return html


def process_xml_file(xml_path, output_dir):
    """Главная функция обработки XML файла."""
    # Создание выходной директории
    os.makedirs(output_dir, exist_ok=True)

    # Чтение XML
    with open(xml_path, 'r', encoding='utf-8') as f:
        xml_content = f.read()

    # Парсинг статей
    entries = parse_xml_entries(xml_content)

    # Обработка и сохранение
    processed = 0
    for headword, prefix, entry_content in entries:
        try:
            html_content = convert_tei_to_html_span(entry_content)
            full_html = create_html_page(headword, prefix, html_content)

            safe_filename = sanitize_filename(headword)
            file_path = os.path.join(output_dir, f"{safe_filename}.html")

            with open(file_path, 'w', encoding='utf-8') as f:
                f.write(full_html)

            processed += 1
        except Exception as e:
            print(f"Ошибка при обработке '{headword}': {e}")

    return processed


if __name__ == "__main__":
    # Настройки
    INPUT_XML_FILE = '/content/Выпуск_2_Безпристрастный_Вейэр_Отправка_fixed_TEI.xml'  # Путь к входному XML файлу
    OUTPUT_DIR = 'dictionary_output4'   # Путь к папке для HTML файлов
    CREATE_ZIP = True                  # Создавать ли архив после обработки

    # Проверка существования файла
    if not os.path.exists(INPUT_XML_FILE):
        print(f"Ошибка: Файл не найден: {INPUT_XML_FILE}")
    else:
        print(f"Обработка файла: {INPUT_XML_FILE}")

        # Обработка
        total = process_xml_file(INPUT_XML_FILE, OUTPUT_DIR)

        print(f"Обработано статей: {total}")
        print(f"Результаты сохранены в: {OUTPUT_DIR}")

        # Создание архива
        if CREATE_ZIP:
            zip_filename = f"{OUTPUT_DIR}.zip"
            print(f"\nСоздание архива: {zip_filename}")

            with zipfile.ZipFile(zip_filename, 'w', zipfile.ZIP_DEFLATED) as zipf:
                for filename in os.listdir(OUTPUT_DIR):
                    file_path = os.path.join(OUTPUT_DIR, filename)
                    if os.path.isfile(file_path):
                        zipf.write(file_path, filename)